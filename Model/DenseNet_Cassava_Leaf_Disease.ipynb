{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObT1bpRCp6TR"
   },
   "source": [
    "#Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uy5XC5kSp_i0",
    "outputId": "2c1d3624-72e9-47a2-c674-a199eaedc235"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tz4jsgfZqAfv"
   },
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import WeightedRandomSampler, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdou3q8qqHoQ"
   },
   "outputs": [],
   "source": [
    "data_dir = 'PyTorch_Image_Classifier/flowers'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hCiwV_J-qLM_",
    "outputId": "be403ec2-293d-4f57-de85-44c8251ba8c3"
   },
   "outputs": [],
   "source": [
    "!pip install kaggle \n",
    "!pip install --upgrade --force-reinstall --no-deps kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hc5JvZPqSfV"
   },
   "source": [
    "# Download Kaggle Cassava Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-mY_-PEzqRRz",
    "outputId": "9383a919-558d-4dfa-93f5-838060b2879f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = \"\" # username from the json file\n",
    "os.environ['KAGGLE_KEY'] = \"\" # key from the json file\n",
    "!kaggle competitions download -c cassava-leaf-disease-classification # api copied from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQwRsAh-qY8B",
    "outputId": "9bc0e061-8037-4bea-8693-24e691b942ba"
   },
   "outputs": [],
   "source": [
    "!unzip cassava-leaf-disease-classification.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3b2eWT8fqec7"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Test Train Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"image_id\"], df[\"label\"], test_size=0.15, random_state=42)\n",
    "\n",
    "#for training and validing\n",
    "train_data, val_data, train_label, val_label = train_test_split(X_train, y_train, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiL2QaGqrACO"
   },
   "source": [
    "# Making Directory In Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4TEfkAK4q_KQ",
    "outputId": "78a4e052-b26b-4655-9c5c-0649826c5721"
   },
   "outputs": [],
   "source": [
    "!mkdir \"train_i\"\n",
    "!mkdir \"val_i\"\n",
    "!mkdir \"test_i\" \n",
    "\n",
    "for label in range(5):\n",
    "  if not os.path.exists(\"train_i/\"+str(label)):\n",
    "    os.makedirs(\"train_i/\"+str(label))\n",
    "  \n",
    "  if not os.path.exists(\"val_i/\"+str(label)):\n",
    "    os.makedirs(\"val_i/\"+str(label))\n",
    "  \n",
    "  if not os.path.exists(\"test_i/\"+str(label)):\n",
    "    os.makedirs(\"test_i/\"+str(label))\n",
    "\n",
    "import os\n",
    "import shutil \n",
    "import os\n",
    "\n",
    "for x,label in zip(train_data,train_label):\n",
    "  #cmd = f\"cp -a /train_images/{x}/. /train_1/\"\n",
    "\n",
    "  send_path = \"/content/train_images/\"+x\n",
    "  print(send_path)\n",
    "  #!mv send_path \"/train_1\"\n",
    "  shutil.move(send_path, \"/content/train_i/\"+str(label)) \n",
    "  \n",
    "for x,label in zip(val_data,val_label):\n",
    "  #cmd = f\"cp -a /train_images/{x}/. /train_1/\"\n",
    "  send_path = \"/content/train_images/\"+x\n",
    "  print(send_path)\n",
    "  #!mv send_path \"/train_1\"\n",
    "  shutil.move(send_path, \"/content/val_i/\"+str(label)) \n",
    "\n",
    "for x,label in zip(X_test,y_test):\n",
    "  #cmd = f\"cp -a /train_images/{x}/. /train_1/\"\n",
    "  send_path = \"/content/train_images/\"+x\n",
    "  print(send_path)\n",
    "  #!mv send_path \"/train_1\"\n",
    "  shutil.move(send_path, \"/content/test_i/\"+str(label))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R6hY5iMTw8hQ",
    "outputId": "98250223-39e2-4611-ec3c-8bbb9495032e"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = Image.open('train_i/0/' + train_data[19689])\n",
    "array = np.array(image)\n",
    "array.shape\n",
    "#plt.imshow(array)\n",
    "#train_label[19689]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYF72_n7raPy"
   },
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WEGj8uIik59U"
   },
   "outputs": [],
   "source": [
    "def get_WeightedSamplerDataLoader(training_dataset,batch_size):\n",
    "  class_weights = {}\n",
    "  sample_weights = [0] * len(training_dataset)\n",
    "\n",
    "  for root, subdir, files in os.walk(\"/content/train_i\"):\n",
    "    if len(root.split(\"/\")) == 4:\n",
    "      class_weights[str(root.split(\"/\")[3])] = round((10/len(files))*100,7)\n",
    "  \n",
    "  for idx, (data,label) in enumerate(training_dataset.imgs):\n",
    "    weights = class_weights[str(label)]\n",
    "    sample_weights[idx] = weights \n",
    "\n",
    "  sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights) , replacement=True)\n",
    "\n",
    "  loader = DataLoader(training_dataset, batch_size = batch_size, sampler= sampler)\n",
    "\n",
    "  return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J9a3pMaXmjeH",
    "outputId": "50672578-905d-4f3c-fe39-879b39478726"
   },
   "outputs": [],
   "source": [
    "for root, subdir, files in os.walk(\"/content/train_i\"):\n",
    "  #print(len(root.split(\"/\")))\n",
    "  if len(root.split(\"/\")) == 4:\n",
    "    #print(\"Belongs to folder \"+str(root.split(\"/\")[3]))\n",
    "    print(len(files))\n",
    "    print((10/len(files))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xLt1mt2rZgj"
   },
   "outputs": [],
   "source": [
    "training_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                          transforms.RandomResizedCrop(224),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.RandomVerticalFlip(),\n",
    "                                          transforms.ColorJitter(brightness=0.10, contrast=0.2, saturation=0.2, hue=0.00),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                               [0.229, 0.224, 0.225])])\n",
    "\n",
    "validation_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                            transforms.CenterCrop(224),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                                 [0.229, 0.224, 0.225])])\n",
    "\n",
    "testing_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                         transforms.CenterCrop(224),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406], # This is Mean\n",
    "                                                              [0.229, 0.224, 0.225])]) # This Standard Deviation\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "training_dataset = datasets.ImageFolder(\"train_i/\", transform=training_transforms)\n",
    "validation_dataset = datasets.ImageFolder(\"val_i/\", transform=validation_transforms)\n",
    "testing_dataset = datasets.ImageFolder(\"test_i/\", transform=testing_transforms)\n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "#train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=32, shuffle=True)\n",
    "train_loader = get_WeightedSamplerDataLoader(training_dataset,64)\n",
    "validate_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=32)\n",
    "test_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "98855ab108a5486fbf4bf7c8109fba01",
      "df5d627181854c34814f062992cc9f5e",
      "30ef5b8ef981499ebb92f497512d2bf0",
      "c2c3224bacd447fca5e5fe32809c15af",
      "2895b169a21a47718e7f075e8dde4f4b",
      "367773ad09c84d5d94c3433ca3b9dec7",
      "f74cd2a05d2c4ea3b5ef19da69bb584e",
      "1ceb1f6bb4d74d26af748e2616bab7c5"
     ]
    },
    "id": "g8IAcXN7rub7",
    "outputId": "807303bf-390a-45d4-f77c-42f24fcc83fb"
   },
   "outputs": [],
   "source": [
    "# Build and train your network\n",
    "# Transfer Learning\n",
    "#model = torch.hub.load('pytorch/vision:v0.6.0', 'densenet121', pretrained=True)\n",
    "model = torchvision.models.densenet121(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JckR8zCZr2aF",
    "outputId": "03338de6-f862-4d56-e0da-f19d4eaa7102"
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w455LchwHULi"
   },
   "outputs": [],
   "source": [
    "# Function for the validation pass\n",
    "def validation(model, validateloader, criterion):\n",
    "    \n",
    "    val_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    for images, labels in iter(validateloader):\n",
    "\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "\n",
    "        output = model.forward(images)\n",
    "        val_loss += criterion(output, labels).item()\n",
    "\n",
    "        probabilities = torch.exp(output)\n",
    "        \n",
    "        equality = (labels.data == probabilities.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return val_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JwkGHIaOr-9P"
   },
   "outputs": [],
   "source": [
    "# Freeze pretrained model parameters to avoid backpropogating through them\n",
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "model.classifier = nn.Linear(1024, 5)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized\n",
    "optimizer = optim.SGD(model.classifier.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.AdamW(model.classifier.parameters(), lr=0.001,eps=1e-08, weight_decay=0.01)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "#exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "quHHdjvuB9_T",
    "outputId": "4a96755f-031b-4630-8958-d4d2ed5ae8d7"
   },
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "\n",
    "#from workspace_utils import active_session\n",
    "\n",
    "def train_classifier():\n",
    "\n",
    "    #with active_session():\n",
    "\n",
    "      epochs = 15\n",
    "      steps = 0\n",
    "      print_every = 40\n",
    "\n",
    "      model.to('cuda')\n",
    "\n",
    "      for e in range(epochs):\n",
    "      \n",
    "          model.train()\n",
    "\n",
    "          running_loss = 0\n",
    "  \n",
    "          for images, labels in iter(train_loader):\n",
    "      \n",
    "              steps += 1\n",
    "      \n",
    "              images, labels = images.to('cuda'), labels.to('cuda')\n",
    "      \n",
    "              optimizer.zero_grad()\n",
    "      \n",
    "              output = model.forward(images)\n",
    "              loss = criterion(output, labels)\n",
    "              loss.backward()\n",
    "              optimizer.step()\n",
    "      \n",
    "              running_loss += loss.item()\n",
    "      \n",
    "              if steps % print_every == 0:\n",
    "              \n",
    "                  model.eval()\n",
    "              \n",
    "                  # Turn off gradients for validation, saves memory and computations\n",
    "                  with torch.no_grad():\n",
    "                      validation_loss, accuracy = validation(model, validate_loader, criterion)\n",
    "          \n",
    "                  print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                        \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                        \"Validation Loss: {:.3f}.. \".format(validation_loss/len(validate_loader)),\n",
    "                        \"Validation Accuracy: {:.3f}\".format(accuracy/len(validate_loader)))\n",
    "          \n",
    "                  running_loss = 0\n",
    "                  #exp_lr_scheduler.step()\n",
    "                  model.train()\n",
    "                  \n",
    "train_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oLOzGPukDIVj",
    "outputId": "f09484f6-ae9e-4660-fdbd-b0b9ced490e0"
   },
   "outputs": [],
   "source": [
    "def test_accuracy(model, test_loader):\n",
    "\n",
    "    # Do validation on the test set\n",
    "    model.eval()\n",
    "    model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        accuracy = 0\n",
    "    \n",
    "        for images, labels in iter(test_loader):\n",
    "    \n",
    "            images, labels = images.to('cuda'), labels.to('cuda')\n",
    "    \n",
    "            output = model.forward(images)\n",
    "\n",
    "            probabilities = torch.exp(output)\n",
    "        \n",
    "            equality = (labels.data == probabilities.max(dim=1)[1])\n",
    "        \n",
    "            accuracy += equality.type(torch.FloatTensor).mean()\n",
    "        \n",
    "        print(\"Test Accuracy: {}\".format(accuracy/len(test_loader)))    \n",
    "        \n",
    "        \n",
    "test_accuracy(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-diIpUqjXEQ"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(model):\n",
    "\n",
    "    model.class_to_idx = training_dataset.class_to_idx\n",
    "\n",
    "    checkpoint = {'arch': \"DenseNet121\",\n",
    "                  'class_to_idx': model.class_to_idx,\n",
    "                  'model_state_dict': model.state_dict()\n",
    "                 }\n",
    "\n",
    "    torch.save(checkpoint, 'checkpoint_DenseNet_PreTrained_NoFreeze_AdamW_0.005.pth')\n",
    "    \n",
    "#save_checkpoint(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bxC0sloD7P6v"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Function that loads a checkpoint and rebuilds the model\n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "\n",
    "    checkpoint = torch.load(filepath, map_location=torch.device('cpu'))\n",
    "    \n",
    "    if checkpoint['arch'] == 'DenseNet121':\n",
    "        \n",
    "        model = torchvision.models.densenet121(pretrained=True)\n",
    "        \n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    else:\n",
    "        print(\"Architecture not recognized.\")\n",
    "    \n",
    "    #model.class_to_idx = checkpoint['class_to_idx']\n",
    "    \n",
    "#     model.classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(1024, 512)),\n",
    "#                                     ('relu', nn.ReLU()),\n",
    "#                                     ('drop', nn.Dropout(p=0.5)),\n",
    "#                                     ('fc2', nn.Linear(512, 5)),\n",
    "#                                     ('output', nn.LogSoftmax(dim=1))]))\n",
    "\n",
    "    model.classifier = nn.Linear(1024, 5)\n",
    "    \n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = load_checkpoint('checkpoint_DenseNet_PreTrained_NoFreeze_AdamW_0.005.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "testing_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                         transforms.CenterCrop(224),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406], # This is Mean\n",
    "                                                              [0.229, 0.224, 0.225])]) # This Standard Deviation\n",
    "\n",
    "test_img = Image.open(r'C:\\Users\\rehma\\Documents\\Python Scripts\\Kaggle\\cassava-leaf-disease-classification\\test_images\\2216849948.jpg')\n",
    "array = np.array(test_img)\n",
    "plt.imshow(array)\n",
    "tranform_test_image = testing_transforms(test_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tranform_test_image.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.forward(tranform_test_image[None])\n",
    "probabilities = torch.exp(output)\n",
    "probabilities.max(dim=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tranform_test_image[None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cassava-leaf-disease-classification\\sample_submission.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = probabilities.max(dim=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DenseNet_Cassava_Leaf_Disease.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1ceb1f6bb4d74d26af748e2616bab7c5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2895b169a21a47718e7f075e8dde4f4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "30ef5b8ef981499ebb92f497512d2bf0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_367773ad09c84d5d94c3433ca3b9dec7",
      "max": 32342954,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2895b169a21a47718e7f075e8dde4f4b",
      "value": 32342954
     }
    },
    "367773ad09c84d5d94c3433ca3b9dec7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98855ab108a5486fbf4bf7c8109fba01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_30ef5b8ef981499ebb92f497512d2bf0",
       "IPY_MODEL_c2c3224bacd447fca5e5fe32809c15af"
      ],
      "layout": "IPY_MODEL_df5d627181854c34814f062992cc9f5e"
     }
    },
    "c2c3224bacd447fca5e5fe32809c15af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ceb1f6bb4d74d26af748e2616bab7c5",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f74cd2a05d2c4ea3b5ef19da69bb584e",
      "value": " 30.8M/30.8M [00:00&lt;00:00, 44.2MB/s]"
     }
    },
    "df5d627181854c34814f062992cc9f5e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f74cd2a05d2c4ea3b5ef19da69bb584e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
