{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-28T15:19:06.726630Z",
     "iopub.status.busy": "2021-01-28T15:19:06.725796Z",
     "iopub.status.idle": "2021-01-28T15:19:06.728666Z",
     "shell.execute_reply": "2021-01-28T15:19:06.728091Z"
    },
    "papermill": {
     "duration": 0.024305,
     "end_time": "2021-01-28T15:19:06.728770",
     "exception": false,
     "start_time": "2021-01-28T15:19:06.704465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/working/train_i/'):\n",
    "    print(\"Dir = \"+ str(dirname) +\" No. Of Images = \"+str(len(filenames)))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T15:19:06.763337Z",
     "iopub.status.busy": "2021-01-28T15:19:06.762706Z",
     "iopub.status.idle": "2021-01-28T15:19:08.520262Z",
     "shell.execute_reply": "2021-01-28T15:19:08.520970Z"
    },
    "papermill": {
     "duration": 1.77836,
     "end_time": "2021-01-28T15:19:08.521211",
     "exception": false,
     "start_time": "2021-01-28T15:19:06.742851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T15:19:08.555335Z",
     "iopub.status.busy": "2021-01-28T15:19:08.554774Z",
     "iopub.status.idle": "2021-01-28T15:19:09.727233Z",
     "shell.execute_reply": "2021-01-28T15:19:09.725864Z"
    },
    "papermill": {
     "duration": 1.191777,
     "end_time": "2021-01-28T15:19:09.727353",
     "exception": false,
     "start_time": "2021-01-28T15:19:08.535576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import WeightedRandomSampler, DataLoader\n",
    "\n",
    "from shutil import copyfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013546,
     "end_time": "2021-01-28T15:19:09.756112",
     "exception": false,
     "start_time": "2021-01-28T15:19:09.742566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading Data and spliting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T15:19:09.790249Z",
     "iopub.status.busy": "2021-01-28T15:19:09.789659Z",
     "iopub.status.idle": "2021-01-28T15:19:09.813159Z",
     "shell.execute_reply": "2021-01-28T15:19:09.812713Z"
    },
    "papermill": {
     "duration": 0.042796,
     "end_time": "2021-01-28T15:19:09.813259",
     "exception": false,
     "start_time": "2021-01-28T15:19:09.770463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/cassava-leaf-disease-classification/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T15:19:09.854758Z",
     "iopub.status.busy": "2021-01-28T15:19:09.854216Z",
     "iopub.status.idle": "2021-01-28T15:19:09.862413Z",
     "shell.execute_reply": "2021-01-28T15:19:09.861960Z"
    },
    "papermill": {
     "duration": 0.035495,
     "end_time": "2021-01-28T15:19:09.862499",
     "exception": false,
     "start_time": "2021-01-28T15:19:09.827004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014354,
     "end_time": "2021-01-28T15:19:09.891019",
     "exception": false,
     "start_time": "2021-01-28T15:19:09.876665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Spliting 90% data for training and 10% for testing. With 90% again spliting it further into 80% for Training 20% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T15:19:09.926185Z",
     "iopub.status.busy": "2021-01-28T15:19:09.925594Z",
     "iopub.status.idle": "2021-01-28T15:19:10.043608Z",
     "shell.execute_reply": "2021-01-28T15:19:10.043145Z"
    },
    "papermill": {
     "duration": 0.138384,
     "end_time": "2021-01-28T15:19:10.043706",
     "exception": false,
     "start_time": "2021-01-28T15:19:09.905322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Train Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"image_id\"], df[\"label\"], test_size=0.10, random_state=42)\n",
    "\n",
    "#for training and validing\n",
    "train_data, val_data, train_label, val_label = train_test_split(X_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014165,
     "end_time": "2021-01-28T15:19:10.072372",
     "exception": false,
     "start_time": "2021-01-28T15:19:10.058207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Making folders for PyTorch to read dataset in right order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T15:19:10.128667Z",
     "iopub.status.busy": "2021-01-28T15:19:10.118959Z",
     "iopub.status.idle": "2021-01-28T15:21:07.434059Z",
     "shell.execute_reply": "2021-01-28T15:21:07.432896Z"
    },
    "papermill": {
     "duration": 117.34741,
     "end_time": "2021-01-28T15:21:07.434247",
     "exception": false,
     "start_time": "2021-01-28T15:19:10.086837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir \"train_i\"\n",
    "!mkdir \"val_i\"\n",
    "!mkdir \"test_i\" \n",
    "\n",
    "for label in range(5):\n",
    "  if not os.path.exists(\"train_i/\"+str(label)):\n",
    "    os.makedirs(\"train_i/\"+str(label))\n",
    "  \n",
    "  if not os.path.exists(\"val_i/\"+str(label)):\n",
    "    os.makedirs(\"val_i/\"+str(label))\n",
    "  \n",
    "  if not os.path.exists(\"test_i/\"+str(label)):\n",
    "    os.makedirs(\"test_i/\"+str(label))\n",
    "\n",
    "path = \"/kaggle/input/cassava-leaf-disease-classification/train_images/\"    \n",
    "for x,label in zip(train_data,train_label):\n",
    "    send_path = path+x\n",
    "    copyfile(src = send_path, dst = \"/kaggle/working/train_i/\"+str(label)+\"/\"+x)\n",
    "  \n",
    "for x,label in zip(val_data,val_label):\n",
    "    send_path = path+x\n",
    "    copyfile(src = send_path, dst = \"/kaggle/working/val_i/\"+str(label)+\"/\"+x) \n",
    "\n",
    "for x,label in zip(X_test,y_test):\n",
    "    send_path = path+x\n",
    "    copyfile(send_path,dst = \"/kaggle/working/test_i/\"+str(label)+\"/\"+x)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.049382,
     "end_time": "2021-01-28T15:21:07.500202",
     "exception": false,
     "start_time": "2021-01-28T15:21:07.450820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T15:21:07.541265Z",
     "iopub.status.busy": "2021-01-28T15:21:07.540088Z",
     "iopub.status.idle": "2021-01-28T15:21:07.543013Z",
     "shell.execute_reply": "2021-01-28T15:21:07.542596Z"
    },
    "papermill": {
     "duration": 0.027602,
     "end_time": "2021-01-28T15:21:07.543101",
     "exception": false,
     "start_time": "2021-01-28T15:21:07.515499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# As our sample data is imbalance so we need to upsample it \n",
    "def get_WeightedSamplerDataLoader(training_dataset,batch_size,path):\n",
    "    class_weights = {}\n",
    "    sample_weights = [0] * len(training_dataset)\n",
    "    \n",
    "    for root, subdir, files in os.walk(path):\n",
    "        if(len(files)>0):\n",
    "            #print(root.split(\"/\"))\n",
    "            if len(root.split(\"/\")) == 5:\n",
    "                class_weights[str(root.split(\"/\")[4])] = round((10/len(files))*100,7)\n",
    "  \n",
    "    for idx, (data,label) in enumerate(training_dataset.imgs):\n",
    "        #print(class_weights)\n",
    "        weights = class_weights[str(label)]\n",
    "        sample_weights[idx] = weights \n",
    "\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights) , replacement=True)\n",
    "\n",
    "    loader = DataLoader(training_dataset, batch_size = batch_size, sampler= sampler,num_workers=4)\n",
    "\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014288,
     "end_time": "2021-01-28T15:21:07.571973",
     "exception": false,
     "start_time": "2021-01-28T15:21:07.557685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To increase the training example and to prevent our model from overfitting we have to apply different trainformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T15:21:07.613395Z",
     "iopub.status.busy": "2021-01-28T15:21:07.612620Z",
     "iopub.status.idle": "2021-01-28T15:21:07.763891Z",
     "shell.execute_reply": "2021-01-28T15:21:07.763434Z"
    },
    "papermill": {
     "duration": 0.177438,
     "end_time": "2021-01-28T15:21:07.763982",
     "exception": false,
     "start_time": "2021-01-28T15:21:07.586544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                          transforms.RandomResizedCrop(224),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.RandomVerticalFlip(),\n",
    "                                          transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.1, hue=0.00),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                               [0.229, 0.224, 0.225])])\n",
    "\n",
    "validation_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                            transforms.CenterCrop(224),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                                 [0.229, 0.224, 0.225])])\n",
    "\n",
    "testing_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                         transforms.CenterCrop(224),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406], # This is Mean\n",
    "                                                              [0.229, 0.224, 0.225])]) # This Standard Deviation\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "training_dataset = datasets.ImageFolder(\"/kaggle/working/train_i/\", transform=training_transforms)\n",
    "validation_dataset = datasets.ImageFolder(\"/kaggle/working/val_i/\", transform=validation_transforms)\n",
    "testing_dataset = datasets.ImageFolder(\"/kaggle/working/test_i/\", transform=testing_transforms)\n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "#train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=32, shuffle=True)\n",
    "train_loader = get_WeightedSamplerDataLoader(training_dataset,16,\"/kaggle/working/train_i\")\n",
    "validate_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=32)\n",
    "test_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014492,
     "end_time": "2021-01-28T15:21:07.793311",
     "exception": false,
     "start_time": "2021-01-28T15:21:07.778819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model EfficientNet_b0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T15:21:07.827362Z",
     "iopub.status.busy": "2021-01-28T15:21:07.826620Z",
     "iopub.status.idle": "2021-01-28T15:23:38.091044Z",
     "shell.execute_reply": "2021-01-28T15:23:38.090017Z"
    },
    "papermill": {
     "duration": 150.283234,
     "end_time": "2021-01-28T15:23:38.091191",
     "exception": false,
     "start_time": "2021-01-28T15:21:07.807957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T15:23:38.137743Z",
     "iopub.status.busy": "2021-01-28T15:23:38.128936Z",
     "iopub.status.idle": "2021-01-28T15:23:38.221430Z",
     "shell.execute_reply": "2021-01-28T15:23:38.220609Z"
    },
    "papermill": {
     "duration": 0.113296,
     "end_time": "2021-01-28T15:23:38.221529",
     "exception": false,
     "start_time": "2021-01-28T15:23:38.108233",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained(\"efficientnet-b0\",advprop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T15:23:38.262690Z",
     "iopub.status.busy": "2021-01-28T15:23:38.262002Z",
     "iopub.status.idle": "2021-01-28T15:23:38.264372Z",
     "shell.execute_reply": "2021-01-28T15:23:38.264862Z"
    },
    "papermill": {
     "duration": 0.026352,
     "end_time": "2021-01-28T15:23:38.264964",
     "exception": false,
     "start_time": "2021-01-28T15:23:38.238612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function for the validation pass\n",
    "def validation(model, validateloader, criterion):\n",
    "    \n",
    "    val_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    for images, labels in iter(validateloader):\n",
    "\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "\n",
    "        output = model.forward(images)\n",
    "        val_loss += criterion(output, labels).item()\n",
    "\n",
    "        probabilities = torch.exp(output)\n",
    "        \n",
    "        equality = (labels.data == probabilities.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return val_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T15:23:38.310449Z",
     "iopub.status.busy": "2021-01-28T15:23:38.302477Z",
     "iopub.status.idle": "2021-01-28T15:23:38.313722Z",
     "shell.execute_reply": "2021-01-28T15:23:38.314260Z"
    },
    "papermill": {
     "duration": 0.032115,
     "end_time": "2021-01-28T15:23:38.314360",
     "exception": false,
     "start_time": "2021-01-28T15:23:38.282245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T15:23:38.361496Z",
     "iopub.status.busy": "2021-01-28T15:23:38.354033Z",
     "iopub.status.idle": "2021-01-28T15:23:38.364789Z",
     "shell.execute_reply": "2021-01-28T15:23:38.365364Z"
    },
    "papermill": {
     "duration": 0.033672,
     "end_time": "2021-01-28T15:23:38.365468",
     "exception": false,
     "start_time": "2021-01-28T15:23:38.331796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = True\n",
    "\n",
    "model._fc = nn.Linear(1280, 5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model._fc.parameters(), lr=1e-4,\n",
    "                                weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T15:23:38.426034Z",
     "iopub.status.busy": "2021-01-28T15:23:38.425187Z",
     "iopub.status.idle": "2021-01-28T15:23:38.429326Z",
     "shell.execute_reply": "2021-01-28T15:23:38.428866Z"
    },
    "papermill": {
     "duration": 0.045854,
     "end_time": "2021-01-28T15:23:38.429410",
     "exception": false,
     "start_time": "2021-01-28T15:23:38.383556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "\n",
    "#from workspace_utils import active_session\n",
    "\n",
    "def train_classifier():\n",
    "\n",
    "    #with active_session():\n",
    "\n",
    "      epochs = 8\n",
    "      steps = 0\n",
    "      print_every = 40\n",
    "      if torch.cuda.is_available(): \n",
    "        model.to('cuda')\n",
    "\n",
    "\n",
    "      for e in range(epochs):\n",
    "      \n",
    "          model.train()\n",
    "\n",
    "          running_loss = 0\n",
    "  \n",
    "          for images, labels in iter(train_loader):\n",
    "      \n",
    "              steps += 1\n",
    "      \n",
    "              images, labels = images.to('cuda'), labels.to('cuda')\n",
    "      \n",
    "              optimizer.zero_grad()\n",
    "      \n",
    "              output = model.forward(images)\n",
    "              loss = criterion(output, labels)\n",
    "              loss.backward()\n",
    "              optimizer.step()\n",
    "      \n",
    "              running_loss += loss.item()\n",
    "      \n",
    "              if steps % print_every == 0:\n",
    "              \n",
    "                  model.eval()\n",
    "              \n",
    "                  # Turn off gradients for validation, saves memory and computations\n",
    "                  with torch.no_grad():\n",
    "                      validation_loss, accuracy = validation(model, validate_loader, criterion)\n",
    "          \n",
    "                  print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                        \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                        \"Validation Loss: {:.3f}.. \".format(validation_loss/len(validate_loader)),\n",
    "                        \"Validation Accuracy: {:.3f}\".format(accuracy/len(validate_loader)))\n",
    "          \n",
    "                  running_loss = 0\n",
    "                  #exp_lr_scheduler.step()\n",
    "                  model.train()\n",
    "                  \n",
    "train_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T15:23:38.480507Z",
     "iopub.status.busy": "2021-01-28T15:23:38.479015Z",
     "iopub.status.idle": "2021-01-28T15:23:38.484459Z",
     "shell.execute_reply": "2021-01-28T15:23:38.484038Z"
    },
    "papermill": {
     "duration": 0.036474,
     "end_time": "2021-01-28T15:23:38.484543",
     "exception": false,
     "start_time": "2021-01-28T15:23:38.448069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_accuracy(model, test_loader):\n",
    "\n",
    "    # Do validation on the test set\n",
    "    model.eval()\n",
    "    model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        accuracy = 0\n",
    "    \n",
    "        for images, labels in iter(test_loader):\n",
    "    \n",
    "            images, labels = images.to('cuda'), labels.to('cuda')\n",
    "    \n",
    "            output = model.forward(images)\n",
    "\n",
    "            probabilities = torch.exp(output)\n",
    "        \n",
    "            equality = (labels.data == probabilities.max(dim=1)[1])\n",
    "        \n",
    "            accuracy += equality.type(torch.FloatTensor).mean()\n",
    "        \n",
    "        print(\"Test Accuracy: {}\".format(accuracy/len(test_loader)))    \n",
    "        \n",
    "        \n",
    "test_accuracy(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018984,
     "end_time": "2021-01-28T15:23:38.522619",
     "exception": false,
     "start_time": "2021-01-28T15:23:38.503635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T15:23:38.566878Z",
     "iopub.status.busy": "2021-01-28T15:23:38.566361Z",
     "iopub.status.idle": "2021-01-28T15:23:38.907399Z",
     "shell.execute_reply": "2021-01-28T15:23:38.907867Z"
    },
    "papermill": {
     "duration": 0.365955,
     "end_time": "2021-01-28T15:23:38.907993",
     "exception": false,
     "start_time": "2021-01-28T15:23:38.542038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "test_img = Image.open(r'/kaggle/input/cassava-leaf-disease-classification/test_images/2216849948.jpg')\n",
    "array = np.array(test_img)\n",
    "plt.imshow(array)\n",
    "\n",
    "tranform_test_image = testing_transforms(test_img)\n",
    "\n",
    "output = model.forward(tranform_test_image[None].to('cuda'))\n",
    "probabilities = torch.exp(output)\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/cassava-leaf-disease-classification/sample_submission.csv\")\n",
    "df[\"label\"] = probabilities.max(dim=1)[1].to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-28T15:23:38.960789Z",
     "iopub.status.busy": "2021-01-28T15:23:38.960233Z",
     "iopub.status.idle": "2021-01-28T15:23:39.236362Z",
     "shell.execute_reply": "2021-01-28T15:23:39.235334Z"
    },
    "papermill": {
     "duration": 0.303985,
     "end_time": "2021-01-28T15:23:39.236482",
     "exception": false,
     "start_time": "2021-01-28T15:23:38.932497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.024227,
     "end_time": "2021-01-28T15:23:39.285071",
     "exception": false,
     "start_time": "2021-01-28T15:23:39.260844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "papermill": {
   "duration": 277.841245,
   "end_time": "2021-01-28T15:23:40.504738",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-28T15:19:02.663493",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
